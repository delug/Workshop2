{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mathematics Behind Data Science\n",
    "\n",
    "This workshop will cover material ranging from what a vector is all the way to L<sup>p</sup> norms, loss functions, and gradient descent! We want to emphasize that a strong math background is not required for this workshop, as we'll be presenting the material in a beginner oriented, hands-on way. That means that we will introduce material both in terms of what you may code up in any given project, and the abstract math objects which represent them. In the simplest case, a vector can be described as a 1D array, but that's not enough to justify many of the techniques employed in DL. In order to extend that, we will dive into the math that powers the code. Specifically, this workshop aims to cover:\n",
    "\n",
    "- Tensors\n",
    "    - Vectors\n",
    "    - Matrices\n",
    "    - Tensors (multi-dimensional arrays)\n",
    "\n",
    "- Functional Reduction\n",
    "- Norms\n",
    "    - Euclidean Distance\n",
    "    - Metrics\n",
    "    - L<sup>1</sup>, L<sup>2</sup>, L<sup>p</sup> norms\n",
    "- Loss Functions\n",
    "    - Mean Squared Error\n",
    "    - Cross Entropy\n",
    "- Derivatives and Jacobians\n",
    "    - Single-variable derivatives\n",
    "    - Multi-variable derivatives (Jacobians)\n",
    "    - Gradients\n",
    "- Dimensionality Reduction\n",
    "    - Principle Component Analysis\n",
    "    - t-SNE\n",
    "    - UMAP\n",
    "- Chain Rule\n",
    "- Computational Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and Data\n",
    "\n",
    "### Vectors\n",
    "\n",
    "Vectors for the basis for the vast majority of data-science but are especially significant in deep learning! To begin with, vectors are the most fundamental way by which we represent data. Ultimately, a vector can be considered a \"list\" of numbers, with each number being assigned an **index**. These indices give us a way to explicitly refer to the individual elements composing the vector. Extending past that, we'll also talk about the operations that can occur using vectors, and more complex ways to manipulate them. Python doesn't come with any data type that's particularly nice for what we intend to do, so instead we look to Numpy's arrays. Numpy provides us an incredibly convenient way to represent such an abstract, and we'll explore it in great depth throughout this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[5 6 7]\n",
      "[1 2 3 4]\n",
      "\n",
      "1\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "a=[1,2,3,4] # Standard Python list\n",
    "b=np.array([5,6,7]) # Numpy array made based on the given python list\n",
    "c=np.array(a) # Another way to create a numpy array based on an existing list\n",
    "\n",
    "print(a) \n",
    "print(b) # Note the numpy array prints without commas \",\"\n",
    "print(c) # This cleans up the print statement and is helpful for larger constructions\n",
    "\n",
    "print()\n",
    "print(a[0])\n",
    "print(b[1]) # Access elements just as you regularly would\n",
    "print(c[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, a vector is referred to as $N$ *dimensional* if and only if it has exactly $N$ *elements*. A vector is also a *first order tensor*. We're going to draw a sharp distinction between dimensionality and order. In a lot of data science literature, these two are generally interchangably referred to as *dimension*, but that leads to way too many headaches for us to justify using it. We've defined dimensionality for our purposes, so what is order? Well, roughly speaking the order of a vector/matrix/tensor is **the number of indices required to specify which element you're talking about**. So again, a vector is a first order tensor, meaning we need only one index to exactly specify which element we want to access. This is shown in our last example! \n",
    "\n",
    "For notation, we'll write out a vector, such as \"a\" in the code above like this: $\\vec a = \\left<1,2,3,4 \\right>$. Other acceptable notations include: $a=[1,2,3,4]^\\intercal$, or $a=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\end{bmatrix}$. We use the first one because it's honestly just easier, and doesn't mess up vertical spacing unlike *some* methods.\n",
    "\n",
    "Now, suppose we have $\\vec{v}$, an $N$ dimensional vector, and suppose every element will be a real number, then we say that $\\vec{v}\\in\\mathbb{R}^N$ read as *v is an element of R-N* (not *R to the power of N*). If your elements are instead integers, the statement would be $\\vec{v}\\in\\mathbb{Z}^N$. In general, if your elements belong to a set $S$, then you write $\\vec{v}\\in S^N$\n",
    "\n",
    "So if we had a vector $\\vec{u}$ which had 6 elements which are real numbers, we'd write $\\vec{u}\\in\\mathbb{R}^6$. If it had 6 integers instead, $\\vec{u}\\in\\mathbb{Z}^6$. Now suppose 4 of those elements were real numbers, and 2 were integers, then $\\vec{u}\\in\\mathbb{R}^4\\times\\mathbb{Z}^2$. Note that $\\mathbb{R}^6=\\mathbb{R}^3\\times\\mathbb{R}^3$. This language gives us much more flexibility in discussing more complex ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** for convenience, we will stop writing the arrow above the vector, since in context it is generally clear whether or not a variable refers to a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "\n",
    "Many of you may be familiar with matrices, but most of you will have only seen them in passing. A matrix can be defined in many ways, but the most programmer-friendly description is as a **collection of elements**, much like how we defined our vectors! With matrices, however, we need two indices in order to specify which element we're talking about.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "1\n",
      "2\n",
      "4\n",
      "9\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3]\n",
    "          ,[4,5,6]\n",
    "          ,[7,8,9]]) # We'll explain this creation in a little bit\n",
    "\n",
    "print(x)\n",
    "print(x[0,0]) # First row, first column, the top-left element\n",
    "print(x[0,1]) # First row, second column\n",
    "print(x[1,0]) # Second row, first column\n",
    "print(x[2,2]) # Third row, third column, the bottom-right element\n",
    "\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above example, we require two indices (e.g 0,1) in order to specify a particular element. So what exactly happened when we only specified one index? Well, it returned the first row of the matrix. This leads to another interpretation of a matrix: **a list of vectors**. If you have vectors $v_1,v_2,v_3$, then you can construct a matrix $A=[v_1,v_2,v_3]^\\intercal$ where our three vectors serve as *rows* in the matrix. In the above code, $v_1=\\left<1,2,3\\right>$, $v_2=\\left<4,5,6\\right>$, $v_3=\\left<7,8,9\\right>$. This is why when we run `print(x[0])` we get $v_1$. \n",
    "\n",
    "In math literature we generally construct matrices using vectors as their *columns*, and this can cause a bit of confusion. In practice it doesn't matter all too much though, since you can always use a handy function to change your rows to columns and vice versa known as the *transpose*, usually denoted as $A^\\intercal$. In fact, when we defined $A$ originally, we used the transpose so that we could set each $v_i$ as a row instead of column. Let's see it in action below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "[1 2 3]\n",
      "\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n",
      "\n",
      "[1 4 7]\n"
     ]
    }
   ],
   "source": [
    "print(x) # Regular\n",
    "print()\n",
    "print(x[0]) # First row of x\n",
    "\n",
    "print()\n",
    "y=x.transpose()\n",
    "print(y) # Switch rows with columns\n",
    "print()\n",
    "print(y[0]) # First row of y, but first column of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undeniably the most common operation regarding matrices is *matrix multiplication*. This can be a little unintuitive at first, but we hope to help explain the weird behaviour. First off, matrices need to have the right kind of shape before being multiplied together. We say a matrix $A$ is $m\\times n$ when it has $m$ rows and $n$ columns. If we want to multiply matrices $A$ and $B$ to get $C=AB$, then $B$ needs to have the same number of rows as $A$ has columns. So if $A$ is $m\\times n$ then $B$ must be $n\\times l$. Then $C$ would end up being an $m\\times l$ matrix. An easy, albeit mathematically lax, way to figure out shape compatibilities for matrices is that the shape of $C=AB$ is $(m\\times n)\\times(n\\times l)\\implies m\\times (n\\times n) \\times l \\implies m\\times l$. You can imagine it as the inner variable $n$ *canceling out*. Which also helps to remind you that $B$ needs to have the same number of rows as $A$ has columns, else the inner dimensions wouldn't be the same and hence wouldn't cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first matrix:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [1 4]]\n",
      "\n",
      "This is the second matrix:\n",
      "[[5 6]\n",
      " [7 8]]\n",
      "\n",
      "This is their product:\n",
      "[[19 22]\n",
      " [43 50]\n",
      " [33 38]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4],[1,4]]) # A is 3x2\n",
    "B = np.array([[5,6],[7,8]]) # B is 2x2\n",
    "\n",
    "print('This is the first matrix:')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "print('This is the second matrix:')\n",
    "print(B)\n",
    "print()\n",
    "\n",
    "print('This is their product:')\n",
    "\n",
    "#multiplies the 2 matrices together\n",
    "print(np.dot(A,B)) # AB is (3x2)x(2x2)=>3x(2x2)x2=>3x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what exactly is going on here? Let's start with a simple example using $A=[a_1,a_2]$ where $a_i\\in\\mathbb{R}^3$ (note since we're not using the transpose, each $a_i$ is a *column* of $A$), a $3x2$ matrix and $b$, a $2x1$ matrix, which is alternatively just a *vector*. Now we can define $Ab=\\sum_{i=1}^2b_ia_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
